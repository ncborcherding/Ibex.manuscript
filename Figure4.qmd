---
title: "Figure 4"
author: "Nick Borcherding"
format: html
editor: visual
date: 'Compiled: `r format(Sys.Date(), "%B %d, %Y")`'
---

To DO List


-   Figure 4C Clustering ARI/Silhouette Comparison

-   Figure 4F: ROC Curve

## Loading Libraries

```{r}
library(Seurat)
library(stringr)
library(Ibex)
library(caret)
library(pROC)
library(igraph)
library(leidenAlg)   
library(mclust)
```

## Defining Custom Functions

```{r}
myBinarySummary <- function(data, lev = NULL, model = NULL) {

  # Positive class is assumed to be lev[2]
  if (length(lev) > 1) {
    positive_class <- lev[2]
  } else {
    positive_class <- lev[1]  # fallback
  }
  
  # Confusion matrix
  CM <- confusionMatrix(data$pred, data$obs, positive = positive_class)
  
  acc  <- CM$overall["Accuracy"]
  kap  <- CM$overall["Kappa"]
  # By-class metrics
  sens <- CM$byClass["Sensitivity"]       # TP / (TP + FN)
  spec <- CM$byClass["Specificity"]       # TN / (TN + FP)
  ppv  <- CM$byClass["Pos Pred Value"]    # TP / (TP + FP)
  npv  <- CM$byClass["Neg Pred Value"]    # TN / (TN + FN)
  f1   <- CM$byClass["F1"]                # 2 * (PPV * Sens) / (PPV + Sens)
  
  out <- c(
    Accuracy = unname(acc),
    Kappa    = unname(kap),
    F1       = unname(f1),
    PPV      = unname(ppv),
    NPV      = unname(npv)
  )
  
  return(out)
}

jaccard_partition <- function(c1, c2) {
  # c1, c2 are integer vectors of cluster memberships
  stopifnot(length(c1) == length(c2))
  
  n <- length(c1)
  pairs_both <- 0
  pairs_either <- 0
  
  # Compare co-clustering in each partition
  for (i in 1:(n-1)){
    for (j in (i+1):n){
      same1 <- (c1[i] == c1[j])
      same2 <- (c2[i] == c2[j])
      
      # If either partition puts i,j together, count it in "either"
      if (same1 || same2) pairs_either <- pairs_either + 1
      # If both partitions put i,j together, count it in "both"
      if (same1 && same2) pairs_both <- pairs_both + 1
    }
  }
  
  # Jaccard index = intersection / union (for co-clustered pairs)
  if (pairs_either == 0) {
    return(NA)  # or 0, depending on preference
  } else {
    return(pairs_both / pairs_either)
  }
}
```

## Processing the Data 

###  Unifying Benisse and Seurat Data

```{r}
# Read the Seurat object
SeuratMerge <- readRDS("./data/processed/Kim2022_SeuratObject.rds")

# Focus on Spike-Specific Yes/No B Cells
SeuratMerge <- subset(SeuratMerge, subset = Spike.Specific %in% c("Yes", "No"))

# Read the BENISSE results
Benisse.results <- read.csv("data/Benisse/outputs/Encoded_Kim2022.csv")

# Extract the metadata (with barcodes in rownames)
SeuratMeta <- SeuratMerge[[]]  
barcodes  <- rownames(SeuratMeta)

# Extract the first token (before "_") from the CTaa column to match 'Benisse.results$index'
IGH.clonotypes <- str_split(SeuratMeta$CTaa, "_", simplify = TRUE)[,1]

# Match clonotypes to Benisse.results$index
match_idx <- match(IGH.clonotypes, Benisse.results$index)

# Subset and reorder the BENISSE results to match the Seurat barcodes
Benisse.results.filtered <- Benisse.results[match_idx, -c(1,22)]

# Give 'Benisse.results.filtered' the same row names as the Seurat object
rownames(Benisse.results.filtered) <- barcodes
gc()
```

### Assembling the Dimensional Reductions

```{r}
arch <- c("CNN", "VAE")
encoders <- c("atchleyFactors", "crucianiProperties", "OHE")

for(i in seq_along(arch)) {
  for(j in seq_along(encoders)) {
    SeuratMerge <- runIbex(SeuratMerge, 
                           chain = "Heavy",
                           method = "encoder",
                           encoder.model = arch[i],
                           encoder.input = encoders[j], 
                           reduction.name = paste0("Ibex.H.", arch[i], ".", encoders[j]))
  }
}

    SeuratMerge <- runIbex(SeuratMerge, 
                           chain = "Heavy",
                           method = "geometric",
                           geometric.theta = pi/3, 
                           reduction.name = "Ibex.H.Geometric")
    
seurat.reductions <- Reductions(SeuratMerge)[7:length(Reductions(SeuratMerge))]

IGH.reduction.list <- lapply(seurat.reductions, function(x) {
                          tmp <- SeuratMerge[[x]]
                          tmp
})

IGH.reduction.list[["Benisse"]] <- Benisse.results.filtered
names(IGH.reduction.list) <- c(seurat.reductions, "Benisse")

# Adding PCA to Latent Dimensions
PCA <- SeuratMerge@reductions$harmony.pca@cell.embeddings

IGH.reduction.list.RNA <- lapply(IGH.reduction.list, function(x) {
  if (class(x) == "DimReduc") {
    tmp <- cbind(x@cell.embeddings, PCA)
  } else {
     tmp <- cbind(x, PCA)
  }
  tmp
})
names(IGH.reduction.list.RNA) <- paste0(names(IGH.reduction.list.RNA), ".PCA")

# Combining Final List to Evaluate
IGH.reduction.list <- c(IGH.reduction.list, IGH.reduction.list.RNA)

IGH.clonotypes <- str_split(SeuratMeta$CTaa, "_", simplify = TRUE)[,1]
Spike.Specific <- as.factor(as.character(SeuratMeta$Spike.Specific))
```

## Figure 4B

```{r}
selected_names <- c("Ibex.H.CNN.atchleyFactors", 
                    "Ibex.H.CNN.crucianiProperties",
                    "Ibex.H.Geometric", 
                    "Benisse")

selected_list <- IGH.reduction.list[selected_names]

pca_results <- lapply(names(selected_list), function(name) {
  if(inherits(selected_list[[name]], "DimReduc")) { 
    dat <- selected_list[[name]]@cell.embeddings
  } else {
    dat <- selected_list[[name]]
  }
  # Remove zero-variance features
  dat <- dat[, apply(dat, 2, sd) != 0]
  
  pca <- prcomp(dat, scale. = TRUE)
  data.frame(PC1 = pca$x[, 1],
             PC2 = pca$x[, 2],
             Sample = rownames(selected_list[[name]]),
             clone = SeuratMerge$CTaa,
             Heavy.V = SeuratMerge$Heavy.V, 
             Heavy.C = SeuratMerge$Heavy.C,
             Spike.Specific = SeuratMerge$Spike.Specific, 
             Cluster = SeuratMerge$leiden_0.18, 
             Group = name)
})

# Combine into a single dataframe
pca_df <- do.call(rbind, pca_results)

cluster.palette <- RColorBrewer::brewer.pal(length(levels(pca_df$Cluster)), "Paired")
cluster.palette <- cluster.palette [c(1,2,3,4,7,8,5,6,9)]

names(cluster.palette) <- levels(pca_df$Cluster)

ggplot(pca_df, aes(x = PC1, y = PC2, color = Cluster)) +
  geom_point(alpha = 0.6, size = 1.5) +
  stat_density_2d(data = subset(pca_df, Spike.Specific == "Yes"), 
                  aes(x = PC1, y = PC2),
                  color = "black", size = 0.3) +
  facet_wrap(~Group, scales = "free") +
  scale_color_manual(values = cluster.palette) +
  theme_void() +
  labs(x = "PC1", y = "PC2")

```

## Figure 4C

```{r}
##################################################
# Cluster each element in the list using Leiden
##################################################
cluster.assignments <- list()

for (reduction_name in names(IGH.reduction.list)) {
  
  # Retrieve the adjacency matrix
  adjacency_mat <- IGH.reduction.list[[reduction_name]]
  
  # Convert to igraph object
  # mode="undirected", weighted=TRUE, diag=FALSE
  g <- graph_from_adjacency_matrix(
    adjmatrix = adjacency_mat,
    mode      = "undirected",
    weighted  = TRUE,
    diag      = FALSE
  )
  
  # Run Leiden clustering
  # Adjust resolution_parameter, n_iterations as needed
  partition <- leiden(
    g,
    resolution_parameter = 1,
    n_iterations = 10
  )
  
  # Store the cluster memberships
  cluster.assignments[[reduction_name]] <- membership(partition)
}


##################################################
# Compare all pairs of cluster solutions
# using ARI and Jaccard
##################################################
all_combinations <- combn(names(cluster.assignments), 2, simplify = FALSE)

comparison_results <- data.frame(
  Method1  = character(), 
  Method2  = character(), 
  ARI      = numeric(), 
  Jaccard  = numeric(),
  stringsAsFactors = FALSE
)

for (comb in all_combinations) {
  c1 <- cluster.assignments[[comb[1]]]
  c2 <- cluster.assignments[[comb[2]]]
  
  # Adjusted Rand Index
  ari_val <- adjustedRandIndex(c1, c2)
  
  # Jaccard index (as defined above for partitions)
  jacc_val <- jaccard_partition(c1, c2)
  
  # Add to results
  comparison_results <- rbind(
    comparison_results,
    data.frame(
      Method1 = comb[1], 
      Method2 = comb[2],
      ARI     = ari_val, 
      Jaccard = jacc_val
    )
  )
}

##################################################
# Visualize the pairwise metrics with ggplot
# (Two examples: ARI heatmap and Jaccard heatmap)
##################################################

# Heatmap-like for ARI
ggplot(comparison_results, aes(x = Method1, y = Method2, fill = ARI)) +
  geom_tile() +
  geom_text(aes(label = round(ARI, 2)), color = "white", size = 4) +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0.5) +
  theme_minimal(base_size = 14) +
  labs(title = "Adjusted Rand Index Between Cluster Partitions") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Heatmap-like for Jaccard
ggplot(comparison_results, aes(x = Method1, y = Method2, fill = Jaccard)) +
  geom_tile() +
  geom_text(aes(label = round(Jaccard, 2)), color = "white", size = 4) +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0.5) +
  theme_minimal(base_size = 14) +
  labs(title = "Jaccard Index Between Cluster Partitions") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```


## Figure 4D

### Create group-based CV folds (no clonotype overlap in train/test)

```{r}
set.seed(123)
unique_clonos <- unique(IGH.clonotypes)

# Create folds at clonotype level
clono_folds <- createFolds(unique_clonos, k = 5, returnTrain = FALSE)

# Initialize index lists
train_index_list <- list()
test_index_list  <- list()

for (fold_i in seq_along(clono_folds)) {
  
  test_clonotypes <- unique_clonos[clono_folds[[fold_i]]]
  
  test_idx <- which(IGH.clonotypes %in% test_clonotypes)
  train_idx <- setdiff(seq_along(IGH.clonotypes), test_idx)
  
  train_index_list[[fold_i]] <- train_idx
  test_index_list[[fold_i]]  <- test_idx
}

# Define caret control object correctly
fitControl <- trainControl(
  method           = "cv",
  number           = 5,
  index            = train_index_list,
  indexOut         = test_index_list,
  classProbs       = TRUE,
  summaryFunction  = myBinarySummary,
  savePredictions  = "final",
  verboseIter      = FALSE
)
```

### Loop over each dimension reduction and each ML method

```{r}
set.seed(123)

ml_methods <- c("ranger", "xgbLinear", "lda", "knn")

# Initialize results container
all_results <- list()

# Define sophisticated parameter tuning
fitControl <- trainControl(
  method = "repeatedcv",
  number = 5,
  repeats = 3,
  summaryFunction = prSummary,
  classProbs = TRUE,
  savePredictions = TRUE,
  verboseIter = FALSE
)

for (reduction_name in names(IGH.reduction.list)) {

  embedding <- IGH.reduction.list[[reduction_name]]

  if (inherits(embedding, "DimReduc")) {
    embedding <- embedding@cell.embeddings
  }

  embedding <- as.data.frame(embedding)

  # Remove zero-variance features
  embedding <- embedding[, apply(embedding, 2, sd) != 0]

  df <- data.frame(embedding, Spike.Specific = Spike.Specific)

  # Apply recipe for standardized feature selection
  rec <- recipe(Spike.Specific ~ ., data = df) %>%
    step_zv(all_predictors()) %>%
    step_corr(all_predictors(), threshold = 0.9) %>%
    step_center(all_predictors()) %>%
    step_scale(all_predictors())

  model_results <- list()
  message("Processing reduction: ", reduction_name)

  for (m in ml_methods) {
    message("Fitting model: ", m)

    set.seed(123)
    fit <- tryCatch({
      train(
        rec,
        data = df,
        method = m,
        metric = "F1",
        trControl = fitControl,
        tuneLength = 10
      )
    }, warning = function(w) {
      message("Warning: ", conditionMessage(w))
      NULL
    }, error = function(e) {
      message("Error: ", e$message)
      NULL
    })

    model_results[[m]] <- fit
  }

  all_results[[reduction_name]] <- model_results
}

# Compile final performance metrics with detailed feature selection quantification
perf_list <- list()

for (reduction_name in names(all_results)) {
  for (m in names(all_results[[reduction_name]])) {
    fit_obj <- all_results[[reduction_name]][[m]]

    if (!is.null(fit_obj)) {
      best <- fit_obj$bestTune
      res_sub <- inner_join(fit_obj$results, best)
      res_sub <- res_sub[1, ]

      # Quantify feature selection (number of features used after preprocessing)
      rec_final <- prep(fit_obj$recipe, training = df)
      num_features <- length(bake(rec_final, new_data = NULL) %>% select(-Spike.Specific))

      perf_list[[paste0(reduction_name, "_", m)]] <- data.frame(
        Reduction = reduction_name,
        Model = m,
        Accuracy = res_sub$Accuracy,
        Kappa = res_sub$Kappa,
        F1 = res_sub$F1,
        PPV = res_sub$Precision,
        NPV = res_sub$Recall,
        Features_Selected = num_features,
        Parameters_Tuned = paste(names(best), best, sep = "=", collapse = ";")
      )
    }
  }
}

final_perf <- bind_rows(perf_list)

# Return final performance results
final_perf
```

### Plotting Results

```{r}
# Select relevant columns and reshape for heatmap
heatmap_data <- final_perf %>%
  select(Model, Reduction, Kappa)

heatmap_data$Reduction <- ifelse(
  heatmap_data$Reduction == "Benisse",
  "Benisse",
  gsub(".*\\.(.*)$", "\\1", heatmap_data$Reduction)
)

# Plot heatmap
plot1 <- ggplot(heatmap_data, aes(x = Model, y = Reduction, fill = Kappa)) +
  geom_tile(color = "white") +
  scale_fill_viridis() +
  theme_minimal() +
  labs(title = "Kappa Values by Model and Reduction",
       x = "Model",
       y = "Reduction",
       fill = "Kappa") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

#############
#PPV Viz
#############

# Select relevant columns and reshape for heatmap
heatmap_data <- final_perf %>%
  select(Model, Reduction, PPV)

heatmap_data$Reduction <- ifelse(
  heatmap_data$Reduction == "Benisse",
  "Benisse",
  gsub(".*\\.(.*)$", "\\1", heatmap_data$Reduction)
)

# Plot heatmap
plot2 <- ggplot(heatmap_data, aes(x = Model, y = Reduction, fill = PPV)) +
  geom_tile(color = "white") +
  scale_fill_viridis() +
  theme_minimal() +
  labs(
       x = "Model",
       y = "Reduction",
       fill = "PPV") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

#############
#NPV Viz
#############

# Select relevant columns and reshape for heatmap
heatmap_data <- final_perf %>%
  select(Model, Reduction, NPV)

heatmap_data$Reduction <- ifelse(
  heatmap_data$Reduction == "Benisse",
  "Benisse",
  gsub(".*\\.(.*)$", "\\1", heatmap_data$Reduction)
)

# Plot heatmap
plot3 <- ggplot(heatmap_data, aes(x = Model, y = Reduction, fill = NPV)) +
  geom_tile(color = "white") +
  scale_fill_viridis() +
  theme_minimal() +
  labs(
       x = "Model",
       y = "Reduction",
       fill = "NPV") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
## Figure 4E 

```{r}
plot_obj <- NULL
plot_colors <- rainbow(length(names(all_results)))  
i <- 1

for (reduction_name in names(all_results)) {
  fit_obj <- all_results[[reduction_name]][[chosen_model]]
  
  best <- fit_obj$bestTune
  pred_df <- fit_obj$pred
  for (tn in names(best)) {
    pred_df <- pred_df[ which(pred_df[[tn]] == best[[tn]]), ]
  }
  
  positive_class <- fit_obj$levels[2]
  roc_obj <- roc(response = pred_df$obs, 
                 predictor = pred_df[[positive_class]], 
                 levels = fit_obj$levels)
  
  if (is.null(plot_obj)) {
    plot_obj <- plot.roc(roc_obj,
                         main = paste("ROC for", chosen_model, "across reductions"),
                         col = plot_colors[i],
                         lwd = 2)
  } else {
    lines.roc(roc_obj, col = plot_colors[i], lwd = 2)
  }
  
  auc_val <- round(auc(roc_obj), 3)
  legend_label <- paste0(reduction_name, " (AUC=", auc_val, ")")
  
  if (i == 1) {
    legend_text <- legend_label
  } else {
    legend_text <- c(legend_text, legend_label)
  }
  
  i <- i + 1
}

# Add a legend
legend("bottomright", legend = legend_text,
       col = plot_colors, lwd = 2, cex = 0.8)

```


## Conclusions

```{r}
sessionInfo()
```
