---
title: "Figure 4"
author: "Nick Borcherding"
format: html
editor: visual
date: 'Compiled: `r format(Sys.Date(), "%B %d, %Y")`'
---

To DO List

-   Figure 4B Dimensional Reductions Overall and by Spike

-   Figure 4C Clustering ARI/Silhouette Comparison

-   Figure 4E: ML Overall Model Summary

-   Figure 4F: ROC Curve

## Loading Libraries

```{r}
library(Seurat)
library(stringr)
library(Ibex)
library(caret)
library(pROC)
```

## Defining Custom Functions

```{r}
myBinarySummary <- function(data, lev = NULL, model = NULL) {

  # Positive class is assumed to be lev[2]
  if (length(lev) > 1) {
    positive_class <- lev[2]
  } else {
    positive_class <- lev[1]  # fallback
  }
  
  # Confusion matrix
  CM <- confusionMatrix(data$pred, data$obs, positive = positive_class)
  
  acc  <- CM$overall["Accuracy"]
  kap  <- CM$overall["Kappa"]
  # By-class metrics
  sens <- CM$byClass["Sensitivity"]       # TP / (TP + FN)
  spec <- CM$byClass["Specificity"]       # TN / (TN + FP)
  ppv  <- CM$byClass["Pos Pred Value"]    # TP / (TP + FP)
  npv  <- CM$byClass["Neg Pred Value"]    # TN / (TN + FN)
  f1   <- CM$byClass["F1"]                # 2 * (PPV * Sens) / (PPV + Sens)
  
  out <- c(
    Accuracy = unname(acc),
    Kappa    = unname(kap),
    F1       = unname(f1),
    PPV      = unname(ppv),
    NPV      = unname(npv)
  )
  
  return(out)
}
```

## Processing the Data 

###  Unifying Benisse and Seurat Data

```{r}
# Read the Seurat object
SeuratMerge <- readRDS("./data/processed/Kim2022_SeuratObject.rds")

# Focus on Spike-Specific Yes/No B Cells
SeuratMerge <- subset(SeuratMerge, subset = Spike.Specific %in% c("Yes", "No"))

# Read the BENISSE results
Benisse.results <- read.csv("data/Benisse/outputs/Encoded_Kim2022.csv")

# Extract the metadata (with barcodes in rownames)
SeuratMeta <- SeuratMerge[[]]  
barcodes  <- rownames(SeuratMeta)

# Extract the first token (before "_") from the CTaa column to match 'Benisse.results$index'
IGH.clonotypes <- str_split(SeuratMeta$CTaa, "_", simplify = TRUE)[,1]

# Match clonotypes to Benisse.results$index
match_idx <- match(IGH.clonotypes, Benisse.results$index)

# Subset and reorder the BENISSE results to match the Seurat barcodes
Benisse.results.filtered <- Benisse.results[match_idx, -c(1,22)]

# Give 'Benisse.results.filtered' the same row names as the Seurat object
rownames(Benisse.results.filtered) <- barcodes
gc()
```

### Assembling the Dimensional Reductions

```{r}
arch <- c("CNN", "VAE")
encoders <- c("atchleyFactors", "crucianiProperties", "OHE")

for(i in seq_along(arch)) {
  for(j in seq_along(encoders)) {
    SeuratMerge <- runIbex(SeuratMerge, 
                           chain = "Heavy",
                           method = "encoder",
                           encoder.model = arch[i],
                           encoder.input = encoders[j], 
                           reduction.name = paste0("Ibex.H.", arch[i], ".", encoders[j]))
  }
}

    SeuratMerge <- runIbex(SeuratMerge, 
                           chain = "Heavy",
                           method = "geometric",
                           geometric.theta = pi/3, 
                           reduction.name = "Ibex.H.Geometric")
    
seurat.reductions <- Reductions(SeuratMerge)[7:length(Reductions(SeuratMerge))]

IGH.reduction.list <- lapply(seurat.reductions, function(x) {
                          tmp <- SeuratMerge[[x]]
                          tmp
})

IGH.reduction.list[["Benisse"]] <- Benisse.results.filtered
names(IGH.reduction.list) <- c(seurat.reductions, "Benisse")

# Adding PCA to Latent Dimensions
PCA <- SeuratMerge@reductions$harmony.pca@cell.embeddings

IGH.reduction.list.RNA <- lapply(IGH.reduction.list, function(x) {
  if (class(x) == "DimReduc") {
    tmp <- cbind(x@cell.embeddings, PCA)
  } else {
     tmp <- cbind(x, PCA)
  }
  tmp
})
names(IGH.reduction.list.RNA) <- paste0(names(IGH.reduction.list.RNA), ".PCA")

# Combining Final List to Evaluate
IGH.reduction.list <- c(IGH.reduction.list, IGH.reduction.list.RNA)

IGH.clonotypes <- str_split(SeuratMeta$CTaa, "_", simplify = TRUE)[,1]
Spike.Specific <- as.factor(as.character(SeuratMeta$Spike.Specific))
```

### Create group-based CV folds (no clonotype overlap in train/test)

```{r}
set.seed(123)
unique_clonos <- unique(IGH.clonotypes)

# Create folds at clonotype level
clono_folds <- createFolds(unique_clonos, k = 5, returnTrain = FALSE)

# Initialize index lists
train_index_list <- list()
test_index_list  <- list()

for (fold_i in seq_along(clono_folds)) {
  
  test_clonotypes <- unique_clonos[clono_folds[[fold_i]]]
  
  test_idx <- which(IGH.clonotypes %in% test_clonotypes)
  train_idx <- setdiff(seq_along(IGH.clonotypes), test_idx)
  
  train_index_list[[fold_i]] <- train_idx
  test_index_list[[fold_i]]  <- test_idx
}

# Define caret control object correctly
fitControl <- trainControl(
  method           = "cv",
  number           = 5,
  index            = train_index_list,
  indexOut         = test_index_list,
  classProbs       = TRUE,
  summaryFunction  = myBinarySummary,
  savePredictions  = "final",
  verboseIter      = FALSE
)
```

### Loop over each dimension reduction and each ML method

```{r}
set.seed(123)

ml_methods <- c("ranger", "xgbLinear", "lda", "knn")

# Initialize results container
all_results <- list()

# Define sophisticated parameter tuning
fitControl <- trainControl(
  method = "repeatedcv",
  number = 5,
  repeats = 3,
  summaryFunction = prSummary,
  classProbs = TRUE,
  savePredictions = TRUE,
  verboseIter = FALSE
)

for (reduction_name in names(IGH.reduction.list)) {

  embedding <- IGH.reduction.list[[reduction_name]]

  if (inherits(embedding, "DimReduc")) {
    embedding <- embedding@cell.embeddings
  }

  embedding <- as.data.frame(embedding)

  # Remove zero-variance features
  embedding <- embedding[, apply(embedding, 2, sd) != 0]

  df <- data.frame(embedding, Spike.Specific = Spike.Specific)

  # Apply recipe for standardized feature selection
  rec <- recipe(Spike.Specific ~ ., data = df) %>%
    step_zv(all_predictors()) %>%
    step_corr(all_predictors(), threshold = 0.9) %>%
    step_center(all_predictors()) %>%
    step_scale(all_predictors())

  model_results <- list()
  message("Processing reduction: ", reduction_name)

  for (m in ml_methods) {
    message("Fitting model: ", m)

    set.seed(123)
    fit <- tryCatch({
      train(
        rec,
        data = df,
        method = m,
        metric = "F1",
        trControl = fitControl,
        tuneLength = 10
      )
    }, warning = function(w) {
      message("Warning: ", conditionMessage(w))
      NULL
    }, error = function(e) {
      message("Error: ", e$message)
      NULL
    })

    model_results[[m]] <- fit
  }

  all_results[[reduction_name]] <- model_results
}

# Compile final performance metrics with detailed feature selection quantification
perf_list <- list()

for (reduction_name in names(all_results)) {
  for (m in names(all_results[[reduction_name]])) {
    fit_obj <- all_results[[reduction_name]][[m]]

    if (!is.null(fit_obj)) {
      best <- fit_obj$bestTune
      res_sub <- inner_join(fit_obj$results, best)
      res_sub <- res_sub[1, ]

      # Quantify feature selection (number of features used after preprocessing)
      rec_final <- prep(fit_obj$recipe, training = df)
      num_features <- length(bake(rec_final, new_data = NULL) %>% select(-Spike.Specific))

      perf_list[[paste0(reduction_name, "_", m)]] <- data.frame(
        Reduction = reduction_name,
        Model = m,
        Accuracy = res_sub$Accuracy,
        Kappa = res_sub$Kappa,
        F1 = res_sub$F1,
        PPV = res_sub$Precision,
        NPV = res_sub$Recall,
        Features_Selected = num_features,
        Parameters_Tuned = paste(names(best), best, sep = "=", collapse = ";")
      )
    }
  }
}

final_perf <- bind_rows(perf_list)

# Return final performance results
final_perf
```

## Figure 4B

```{r}
selected_names <- c("Ibex.H.CNN.atchleyFactors", 
                    "Ibex.H.CNN.crucianiProperties",
                    "Ibex.H.Geometric", 
                    "Benisse")

selected_list <- IGH.reduction.list[selected_names]

pca_results <- lapply(names(selected_list), function(name) {
  if(inherits(selected_list[[name]], "DimReduc")) { 
    dat <- selected_list[[name]]@cell.embeddings
  } else {
    dat <- selected_list[[name]]
  }
  # Remove zero-variance features
  dat <- dat[, apply(dat, 2, sd) != 0]
  
  pca <- prcomp(dat, scale. = TRUE)
  data.frame(PC1 = pca$x[, 1],
             PC2 = pca$x[, 2],
             Sample = rownames(selected_list[[name]]),
             clone = SeuratMerge$CTaa,
             Heavy.V = SeuratMerge$Heavy.V, 
             Heavy.C = SeuratMerge$Heavy.C,
             Spike.Specific = SeuratMerge$Spike.Specific, 
             Cluster = SeuratMerge$leiden_0.18, 
             Group = name)
})

# Combine into a single dataframe
pca_df <- do.call(rbind, pca_results)

cluster.palette <- RColorBrewer::brewer.pal(length(levels(pca_df$Cluster)), "Paired")
cluster.palette <- cluster.palette [c(1,2,3,4,7,8,5,6,9)]

names(cluster.palette) <- levels(pca_df$Cluster)

ggplot(pca_df, aes(x = PC1, y = PC2, color = Cluster)) +
  geom_point(alpha = 0.6, size = 1.5) +
  stat_density_2d(data = subset(pca_df, Spike.Specific == "Yes"), 
                  aes(x = PC1, y = PC2),
                  color = "black", size = 0.3) +
  facet_wrap(~Group, scales = "free") +
  scale_color_manual(values = cluster.palette) +
  theme_void() +
  labs(x = "PC1", y = "PC2")


```

# Conclusions

```{r}
sessionInfo()
```
