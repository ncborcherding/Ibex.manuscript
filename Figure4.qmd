---
title: "Figure 4"
author: "Nick Borcherding"
format: html
editor: visual
date: 'Compiled: `r format(Sys.Date(), "%B %d, %Y")`'
---

To DO List

-   Add RNA component to Prediction Loop

-   Add Tuning for each model by type

-   Figure 4B Dimensional Reductions Overall and by Spike

-   Figure 4C Clustering ARI/Silhouette Comparison

-   Figure 4E: ML Overall Model Summary

-   Figure 4F: ROC Curve

## Loading Libraries

```{r}
library(Seurat)
library(stringr)
library(Ibex)
library(caret)
library(pROC)
```

## Defining Custom Functions

```{r}
myBinarySummary <- function(data, lev = NULL, model = NULL) {

  # Positive class is assumed to be lev[2]
  if (length(lev) > 1) {
    positive_class <- lev[2]
  } else {
    positive_class <- lev[1]  # fallback
  }
  
  # Confusion matrix
  CM <- confusionMatrix(data$pred, data$obs, positive = positive_class)
  
  acc  <- CM$overall["Accuracy"]
  kap  <- CM$overall["Kappa"]
  # By-class metrics
  sens <- CM$byClass["Sensitivity"]       # TP / (TP + FN)
  spec <- CM$byClass["Specificity"]       # TN / (TN + FP)
  ppv  <- CM$byClass["Pos Pred Value"]    # TP / (TP + FP)
  npv  <- CM$byClass["Neg Pred Value"]    # TN / (TN + FN)
  f1   <- CM$byClass["F1"]                # 2 * (PPV * Sens) / (PPV + Sens)
  
  out <- c(
    Accuracy = unname(acc),
    Kappa    = unname(kap),
    F1       = unname(f1),
    PPV      = unname(ppv),
    NPV      = unname(npv)
  )
  
  return(out)
}
```

## Processing the Data 

###  Unifying Benisse and Seurat Data

```{r}
# Read the Seurat object
SeuratMerge <- readRDS("./data/processed/Kim2022_SeuratObject.rds")

# Focus on Spike-Specific Yes/No B Cells
SeuratMerge <- subset(SeuratMerge, subset = Spike.Specific %in% c("Yes", "No"))

# Read the BENISSE results
Benisse.results <- read.csv("data/Benisse/outputs/Encoded_Kim2022.csv")

# Extract the metadata (with barcodes in rownames)
SeuratMeta <- SeuratMerge[[]]  
barcodes  <- rownames(SeuratMeta)

# Extract the first token (before "_") from the CTaa column to match 'Benisse.results$index'
IGH.clonotypes <- str_split(SeuratMeta$CTaa, "_", simplify = TRUE)[,1]

# Match clonotypes to Benisse.results$index
match_idx <- match(IGH.clonotypes, Benisse.results$index)

# Subset and reorder the BENISSE results to match the Seurat barcodes
Benisse.results.filtered <- Benisse.results[match_idx, -c(1,22)]

# Give 'Benisse.results.filtered' the same row names as the Seurat object
rownames(Benisse.results.filtered) <- barcodes
gc()
```

### Assembling the Dimensional Reductions

```{r}
arch <- c("CNN", "VAE")
encoders <- c("atchleyFactors", "crucianiProperties", "OHE")

for(i in seq_along(arch)) {
  for(j in seq_along(encoders)) {
    SeuratMerge <- runIbex(SeuratMerge, 
                           chain = "Heavy",
                           method = "encoder",
                           encoder.model = arch[i],
                           encoder.input = encoders[j], 
                           reduction.name = paste0("Ibex.H.", arch[i], ".", encoders[j]))
  }
}

    SeuratMerge <- runIbex(SeuratMerge, 
                           chain = "Heavy",
                           method = "geometric",
                           geometric.theta = pi/3, 
                           reduction.name = "Ibex.H.Geometric")
    
seurat.reductions <- Reductions(SeuratMerge)[7:length(Reductions(SeuratMerge))]

IGH.reduction.list <- lapply(seurat.reductions, function(x) {
                          tmp <- SeuratMerge[[x]]
                          tmp
})

IGH.reduction.list[["Benisse"]] <- Benisse.results.filtered
names(IGH.reduction.list) <- c(seurat.reductions, "Benisse")

#############################
#Need to Add RNA Values
############################



IGH.clonotypes <- str_split(SeuratMeta$CTaa, "_", simplify = TRUE)[,1]
Spike.Specific <- as.factor(as.character(SeuratMeta$Spike.Specific))
```

### Create group-based CV folds (no clonotype overlap in train/test)

```{r}
set.seed(123)
unique_clonos <- unique(IGH.clonotypes)

# Create folds at clonotype level
clono_folds <- createFolds(unique_clonos, k = 5, returnTrain = FALSE)

# Initialize index lists
train_index_list <- list()
test_index_list  <- list()

for (fold_i in seq_along(clono_folds)) {
  
  test_clonotypes <- unique_clonos[clono_folds[[fold_i]]]
  
  test_idx <- which(IGH.clonotypes %in% test_clonotypes)
  train_idx <- setdiff(seq_along(IGH.clonotypes), test_idx)
  
  train_index_list[[fold_i]] <- train_idx
  test_index_list[[fold_i]]  <- test_idx
}

# Define caret control object correctly
fitControl <- trainControl(
  method           = "cv",
  number           = 5,
  index            = train_index_list,
  indexOut         = test_index_list,
  classProbs       = TRUE,
  summaryFunction  = myBinarySummary,
  savePredictions  = "final",
  verboseIter      = FALSE
)
```

### Loop over each dimension reduction and each ML method

```{r}
ml_methods <- c("ranger", "xgbLinear", "lda", "knn")

# Start looping over reductions and models
all_results <- list()

for (reduction_name in names(IGH.reduction.list)) {
  
  embedding <- IGH.reduction.list[[reduction_name]]
  
  if (class(embedding) == "DimReduc") {
    embedding <- embedding@cell.embeddings
  }
  
  embedding <- as.data.frame(embedding)
  
  # Remove constant columns globally (before training)
  embedding <- embedding[, apply(embedding, 2, sd) != 0]
  embedding[] <- sapply(embedding[], scale)
  
  df <- data.frame(embedding, Spike.Specific = Spike.Specific)
  
  model_results <- list()
  message("Fitting models for reduction: ", reduction_name)
  
  for (m in ml_methods) {
    message("Fitting ", m)
    set.seed(123)
    fit <- tryCatch({
      train(
        Spike.Specific ~ ., 
        data       = df,
        method     = m,
        metric     = "F1",
        trControl  = fitControl
      )
    }, warning = function(w) {
      message("Warning: ", conditionMessage(w))
      NULL
    }, error = function(e) {
      message("Error: ", e$message)
      NULL
    })
    
    model_results[[m]] <- fit
  }
  
  all_results[[reduction_name]] <- model_results
}


# We'll build a data.frame with overall performance 
perf_list <- list()

for (reduction_name in names(all_results)) {
  for (m in names(all_results[[reduction_name]])) {
    fit_obj <- all_results[[reduction_name]][[m]]

    best <- fit_obj$bestTune
    tune_names <- names(best)
    
    res_sub <- fit_obj$results
    for (tn in tune_names) {
      res_sub <- res_sub[ which(res_sub[[tn]] == best[[tn]]), ]
    }
    
    res_sub <- res_sub[1, ]
    
    perf_list[[paste0(reduction_name, "_", m)]] <- data.frame(
      Reduction = reduction_name,
      Model     = m,
      Accuracy  = res_sub$Accuracy,
      Kappa     = res_sub$Kappa,
      F1        = res_sub$F1,
      PPV       = res_sub$PPV,
      NPV       = res_sub$NPV
    )
  }
}

final_perf <- do.call(rbind, perf_list)
final_perf

```

# Conclusions

```{r}
sessionInfo()
```
