---
title: "Figure 1"
author: "Nick Borcherding"
format: html
editor: visual
date: 'Compiled: `r format(Sys.Date(), "%B %d, %Y")`'
---

## Loading Libraries & Functions

```{r}
library(reshape2)
library(dplyr)
library(viridis)
library(stringr)
library(ggplot2)
library(ggthemes)
library(ggpubr)
library(patchwork)
```

## Loading Prelimnary Tuning Data

```{r}
tuned.results <- list.files("~/Documents/GitHub/Ibex.manuscript/data/tuningRuns/Preliminary", 
                                full.names = TRUE)
file.names <- str_split(tuned.results, "/", simplify = TRUE)[,ncol(str_split(tuned.results, "/", simplify = TRUE))]
file.names <- str_remove_all(file.names, ".rds")
chain <- str_split(file.names, "_", simplify = TRUE)[,1]

#Loading Tuning Runs
total.results <- list()
for(x in seq_along(tuned.results)) {
  tmp <- readRDS(tuned.results[x])
  tmp$model <- paste0(tmp$model, "_", chain[x])
  total.results[[x]] <- tmp
}

#Adding Different Groups
tuned.results <- do.call(rbind, total.results)
tuned.results$overall.model <- paste0(tuned.results$method, "_", tuned.results$model)
tuned.results$approach <- ifelse(tuned.results$method == "OHE", "OHE", "AAP")
tuned.results$group <- str_split(tuned.results$model, "_", simplify = TRUE)[,1]

#Ordering Grouping variable
tuned.results$group <- factor(tuned.results$group, levels = c("L1.CNN", "L2.CNN", "L3.CNN",  "L1.VAE", "L2.VAE","L3.VAE"))

tuned.results <- tuned.results %>%
                      filter(as.numeric(score) < 10) 
```

## Figure 1C

Visualization of the effect of the hidden layers (size and number) and latent dimension size on loss.

-   Loss be mean_square_error for all models (even though VAE used a derivative) and represented in -log10(value), the bigger the number, the better the performance

-   Only visualize one layer at a time in terms of effect on loss, will filter out other layers

```{r}
#Scaling values to be comprable
scaled_results <- tuned.results %>%
  group_by(group) %>%
  mutate(scaled_score = (-log10(as.numeric(score)) - min(-log10(as.numeric(score)))) /
           (max(-log10(as.numeric(score))) - min(-log10(as.numeric(score)))))


#############
#Layer 1
#############
plot1 <- ggplot(scaled_results[tuned.results$variable == "hidden_dim1",], 
       aes(x = as.numeric(value), y = scaled_score, color = group)) + 
          geom_smooth(aes(linetype = optimizer, fill = group), 
                      method = "loess", se = TRUE, size = 1) + 
          ylab("Scaled\n-log10(mean squared error)") + 
          xlab("Layer 1 Size") + 
          scale_color_viridis(discrete = TRUE) +
          scale_fill_viridis(discrete = TRUE) +
          facet_grid(.~optimizer) + 
          theme_clean(base_size = 14) +
          guides(linetype = "none") + 
          theme(legend.position = "right", 
                plot.background = element_rect(color = NA))

#################
#Latent Dimensions
#################
plot2 <- ggplot(scaled_results[tuned.results$variable == "latent_dim",], 
       aes(x = as.numeric(value), y = scaled_score, color = group)) + 
          geom_smooth(aes(linetype = optimizer, fill = group), 
                      method = "loess", se = TRUE, size = 1) + 
          ylab("Scaled\n-log10(mean squared error)") + 
          xlab("Latent Dimensions") + 
          scale_color_viridis(discrete = TRUE) +
          scale_fill_viridis(discrete = TRUE) +
          facet_grid(.~optimizer) + 
          theme_clean(base_size = 14) +
          guides(linetype = "none") + 
          theme(legend.position = "right", 
                plot.background = element_rect(color = NA))

plot1 + plot2 + plot_layout(guides = "collect", ncol = 1)
ggsave("./outputs/Figure1/Figure1C.pdf", height = 5.5, width = 10)

#############
#Layer 2
#############la",]
plot3 <- ggplot(scaled_results[tuned.results$variable == "hidden_dim2",], 
               aes(x = as.numeric(value), y = scaled_score, color = group)) + 
                  geom_smooth(aes(linetype = optimizer, fill = group), 
                              method = "loess", se = TRUE, size = 1) + 
                  ylab("Scaled\n-log10(mean squared error)") + 
                  xlab("Layer 2 Size") + 
                  scale_color_viridis(discrete = TRUE) +
                  scale_fill_viridis(discrete = TRUE) +
                  facet_grid(.~optimizer) + 
                  theme_clean(base_size = 14) +
                  guides(linetype = "none") + 
                  theme(legend.position = "right", 
                        plot.background = element_rect(color = NA))

#############
#Layer 3
#############
plot4 <- ggplot(scaled_results[tuned.results$variable == "hidden_dim3",], 
                 aes(x = as.numeric(value), y = scaled_score, color = group)) + 
                    geom_smooth(aes(linetype = optimizer, fill = group), 
                                method = "loess", se = TRUE, size = 1) + 
                    ylab("Scaled\n-log10(mean squared error)") + 
                    xlab("Layer 3 Size") + 
                    scale_color_viridis(discrete = TRUE) +
                    scale_fill_viridis(discrete = TRUE) +
                    facet_grid(.~optimizer) + 
                    theme_clean(base_size = 14) +
                    guides(linetype = "none") + 
                    theme(legend.position = "right", 
                          plot.background = element_rect(color = NA))

plot3 + plot4 + plot_layout(guides = "collect", ncol = 1)
ggsave("./outputs/Supplemental/FigureA.pdf", height = 5.5, width = 10)
```

## Figure 1D

Comparing results for Expanded Sequences (including amino acids from CDR1/2/3). These runs had set optimizer of Adam and activation ReLU.

```{r}
expanded.results <- list.files("~/Documents/GitHub/Ibex.manuscript/data/tuningRuns/ExpandedSequence", 
                               full.names = TRUE)
file.names <- str_split(expanded.results, "/", simplify = TRUE)[,ncol(str_split(expanded.results, "/", simplify = TRUE))]
file.names <- str_remove_all(file.names, ".rds")
chain <- str_split(file.names, "_", simplify = TRUE)[,1]

#Loading Tuning Runs
total.results <- list()
for(x in seq_along(expanded.results)) {
  tmp <- readRDS(expanded.results[x])
  tmp$model <- paste0(tmp$model, "_", chain[x])
  total.results[[x]] <- tmp
}

#Adding Different Groups
expanded.results <- do.call(rbind, total.results)
expanded.results$overall.model <- paste0(expanded.results$method, "_", expanded.results$model)
expanded.results$approach <- ifelse(expanded.results$method == "OHE", "OHE", "AAP")
expanded.results$group <- str_split(expanded.results$model, "_", simplify = TRUE)[,1]

#Ordering Grouping variable
expanded.results$group <- factor(expanded.results$group, levels = c("L1.CNN", "L2.CNN", "L3.CNN",  "L1.VAE", "L2.VAE","L3.VAE"))

#expanded.results <- expanded.results %>%
#                      filter(as.numeric(score) < 10) 


scaled_results <- expanded.results %>%
  group_by(group) %>%
  mutate(scaled_score = (-log10(as.numeric(score)) - min(-log10(as.numeric(score)))) /
           (max(-log10(as.numeric(score))) - min(-log10(as.numeric(score)))))

plot1 <- ggplot(scaled_results[scaled_results$variable == "hidden_dim1",], 
                 aes(x = as.numeric(value), y = scaled_score, color = group)) + 
                    geom_smooth(aes(fill = group), 
                                method = "loess", se = TRUE, size = 1) + 
                    ylab("Scaled\n-log10(mean squared error)") + 
                    xlab("Layer 1 Size") + 
                    scale_color_viridis(discrete = TRUE) +
                    scale_fill_viridis(discrete = TRUE) +
                    theme_clean(base_size = 14) +
                    facet_grid(.~approach) + 
                    guides(linetype = "none") + 
                    theme(legend.position = "right", 
                          plot.background = element_rect(color = NA))

#################
#Latent Dimensions
#################

plot2 <- ggplot(scaled_results[scaled_results$variable == "latent_dim",], 
                 aes(x = as.numeric(value), y = scaled_score, color = group)) + 
                    geom_smooth(aes(fill = group), 
                                method = "loess", se = TRUE, size = 1) + 
                    ylab("Scaled\n-log10(mean squared error)") + 
                    xlab("Latent Dimensions") + 
                    scale_color_viridis(discrete = TRUE) +
                    scale_fill_viridis(discrete = TRUE) +
                    theme_clean(base_size = 14) +
                    facet_grid(.~approach) + 
                    guides(linetype = "none") + 
                    theme(legend.position = "right", 
                          plot.background = element_rect(color = NA))




plot1 + plot2 + plot_layout(guides = "collect", ncol = 2)
ggsave("./outputs/Figure1/Figure1D.pdf", height = 3, width = 10)
```

## Figure 1E

Assessment of the performance of different amino acid property transformations - filtering out any OHE results (by definition not an amino acid property) and any model that uses sgd. The latter is because these models serially under performed compared to ADAM or RMSprop.

We are not worried about what the different parameters affected the performance, so we are filtering on hidden_dim1 as all models have at least 1 layer and we can then plot 1 loss value for each model.

```{r}
tmp.subset <- tuned.results[tuned.results$method != "OHE" & tuned.results$variable == "hidden_dim1" & tuned.results$optimizer != "sgd",]
tmp.subset <- na.omit(tmp.subset)

median.value = tmp.subset %>%
                  group_by(arch) %>%
                  summarise(median_value = median(as.numeric(score)))
median.value$median_value <- -log10(median.value$median_value)
                

ggplot(tmp.subset, 
       aes(x=method, y = -log10(as.numeric(score)))) + 
    geom_boxplot(aes(fill = method), alpha = 0.7) + 
  facet_grid(.~arch, scales = "free_x") + 
  geom_hline(data = median.value, aes(yintercept = median_value), size = 1) + 
  
    ylab("-log10(mean_squared_error)") + 
    xlab("Amino Acid Properties") + 
  scale_x_discrete(limits = rev) + 
  coord_flip() + 
    scale_fill_viridis(discrete = TRUE, direction = -1) + 
  guides(fill = "none") + 
  
  theme_clean() + 
    theme(panel.grid.major = element_blank(), 
          panel.grid.minor = element_blank(),
          panel.background = element_rect(colour = "black", linewidth =1)) 
ggsave("./outputs/Figure1/Figure1E.pdf", height = 4.5, width = 6, dpi = 300)
```

## Figure 1F

Looking at loss as a function of epoch, batch size and learning rate with fixed hidden and latent dimensions.

```{r}
refined.results <- list.files("~/Documents/GitHub/Ibex.manuscript/data/tuningRuns/Refined", 
                                full.names = TRUE)
file.names <- str_split(refined.results, "/", simplify = TRUE)[,ncol(str_split(refined.results, "/", simplify = TRUE))]
file.names <- str_remove_all(file.names, ".rds")
chain <- str_split(file.names, "_", simplify = TRUE)[,1]

#Loading Tuning Runs
total.results <- list()
for(x in seq_along(refined.results)) {
  tmp <- readRDS(refined.results[x])
  tmp$model <- paste0(tmp$model, "_", chain[x])
  total.results[[x]] <- tmp
}

#Adding Different Groups
refined.results <- do.call(rbind, total.results)
refined.results$overall.model <- paste0(refined.results$method)
refined.results$approach <- ifelse(refined.results$method == "OHE", "OHE", "AAP")
refined.results$group <- str_split(refined.results$model, "_", simplify = TRUE)[,1]
refined.results$final.class <- paste0(refined.results$arch, "_", refined.results$overall.model, "_", refined.results$learning_rate, "_", refined.results$batch_size, "_", refined.results$epoch_number)

#Ordering Grouping variable
refined.results$group <- factor(refined.results$group, levels = c("L1.CNN", "L2.CNN", "L3.CNN",  "L1.VAE", "L2.VAE","L3.VAE"))

refined.results <- refined.results %>%
                      filter(data == "validation") %>%
                      group_by(final.class) %>%
                      slice(which.min(as.numeric(value)))

refined.results <- refined.results %>%
                    mutate(E.Stop = as.numeric(epoch_number) - as.numeric(epoch))

plot1 <- refined.results %>%
              group_by(method, epoch_number, arch) %>%  # Group by method and epoch_number
              summarize(mean_E_Stop = mean(E.Stop, na.rm = TRUE), .groups = 'drop') %>%  # Calculate median
              ggplot(aes(y = method, x = as.factor(epoch_number))) + 
              geom_tile(aes(fill = mean_E_Stop), color = "white") +  # Use the median as fill
              scale_fill_viridis() + 
             labs(fill = "Mean Early Stop") +
              theme_clean() +
              facet_grid(.~arch) + 
              theme(axis.title = element_blank(),
                    legend.position = "bottom",
                    legend.key.height = unit(0.6, "cm"),  
                    legend.key.width = unit(0.35, "cm"),   
                    panel.grid = element_blank(),         
                    axis.ticks = element_blank(), 
                    legend.background = element_blank(), 
                    plot.background = element_rect(color = NA)) 
             
plot2 <- refined.results %>%
              group_by(method, batch_size, arch) %>%  
              summarize(mean_E_Stop = mean(E.Stop, na.rm = TRUE), .groups = 'drop') %>%  # Calculate median
              ggplot(aes(y = method, x = as.factor(batch_size))) + 
              geom_tile(aes(fill = mean_E_Stop), color = "white") +  # Use the median as fill
              scale_fill_viridis() + 
              labs(fill = "Mean Early Stop") +
              theme_clean() +
              facet_grid(.~arch) + 
              theme(axis.title = element_blank(),
                    axis.text.y = element_blank(),
                    legend.position = "bottom",
                    legend.key.height = unit(0.6, "cm"),  
                    legend.key.width = unit(0.35, "cm"),   
                    panel.grid = element_blank(),         
                    axis.ticks = element_blank(), 
                    legend.background = element_blank(), 
                    plot.background = element_rect(color = NA))            
             
              
plot3 <- refined.results %>%
              group_by(method, learning_rate, arch) %>%  
              summarize(mean_E_Stop = mean(E.Stop, na.rm = TRUE), .groups = 'drop') %>%  
              ggplot(aes(y = method, x = as.factor(learning_rate))) + 
              geom_tile(aes(fill = mean_E_Stop), color = "white") + 
              scale_fill_viridis() + 
              labs(fill = "Mean Early Stop") +
              theme_clean() +
              facet_grid(.~arch) + 
              theme(axis.title = element_blank(),
                    axis.text.y = element_blank(),
                    legend.position = "bottom",
                    legend.key.height = unit(0.6, "cm"),  
                    legend.key.width = unit(0.35, "cm"),   
                    panel.grid = element_blank(),         
                    axis.ticks = element_blank(), 
                    legend.background = element_blank(), 
                    plot.background = element_rect(color = NA)) 



plot1 + plot2 + plot3 + plot_layout(ncol = 3)
ggsave("./outputs/Figure1/Figure1F.pdf", height = 4.5, width = 10, dpi = 300)
                      
```

## Conclusions

```{r}
sessionInfo()
```
